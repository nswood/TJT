{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeefce5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uscms_data/d3/jkrupa/flat/mambaforge/envs/IN/lib/python3.10/site-packages/fast_soft_sort-0.1-py3.10.egg/fast_soft_sort/third_party/isotonic.py:39: UserWarning: Numba could not be imported. Code will run much more slowly. To install, please run 'pip install numba'.\n"
     ]
    }
   ],
   "source": [
    "# Imports basics\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import setGPU\n",
    "import sklearn\n",
    "import corner\n",
    "import os\n",
    "import scipy\n",
    "# Imports neural net tools\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.variable import *\n",
    "import torch.optim as optim\n",
    "from fast_soft_sort.pytorch_ops import soft_rank\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf55b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378cd508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets controllable values\n",
    "\n",
    "particlesConsidered = 50\n",
    "particlesPostCut = 50\n",
    "entriesPerParticle = 4\n",
    "eventDataLength = 6\n",
    "decayTypeColumn = -1\n",
    "datapoints = 1400000\n",
    "#datapoints = len(totalData)\n",
    "modelName = \"IN_FlatSamples_EighthQCDEighthSig_50particles_pTsdmassfilling_dRlimit08\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "685318e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting\n",
      "(3074667, 207)\n",
      "Preparing Data\n",
      "(3074667, 207)\n",
      "3074667 [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "3074667 [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "3074667 [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "datapoints 1486242\n",
      "[[-0.8218427  -0.9793822   0.82931083 ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.9116873  -1.3553605   0.22445557 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.20539148  1.5885682   0.19883753 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 2.1065607   1.7468735   0.6948912  ...  0.          0.\n",
      "   1.        ]\n",
      " [ 1.0260688  -2.8028588   0.21128003 ...  1.          1.\n",
      "   1.        ]\n",
      " [ 1.3903469   2.9405048   3.047642   ... -1.         -1.\n",
      "   1.        ]]\n",
      "Selecting particlesPostCut\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjMUlEQVR4nO3dfZxXZZ3/8deb4S7zHskHMOhgUCuolY6kpj40NkF+Jd6QoG7rXVoKu1qK6bolmmuyrZGlWQgugi6ji6KYpGuSdKMJgxAKqJCYDJmMRJASwgyf3x/fw/Rl+A7zPTBnbt/Px2MennOd6zrnOsfDfOa6rnOuo4jAzMysWJ1augJmZta2OHCYmVkqDhxmZpaKA4eZmaXiwGFmZql0bukKNIeDDjooysrKWroaZmZtysKFC9+NiJ710ztE4CgrK6OysrKlq2Fm1qZI+kOhdHdVmZlZKg4cZmaWigOHmZml0iHGOMys5WzdupWqqio2b97c0lWxBnTv3p3S0lK6dOlSVH4HDjPLVFVVFfvssw9lZWVIaunqWD0Rwbp166iqqqJfv35FlXFXlZllavPmzfTo0cNBo5WSRI8ePVK1CB04zCxzDhqtW9r/Pw4cZmaWisc4zKx5jR/frPubNWsWN9988w5pS5Ys4cknn+Twww/noosu4rnnntup3LBhw/jtb3/LiSeeyE9/+tO69AsuuIDKykq6dOnC4MGD+clPfkKXLl347ne/y4MPPghATU0Ny5cvp7q6mgMPPJCnnnqKq666itraWr785S9z/fXXA3DSSSfx17/+FYC1a9cyePBgHnvssbpjLViwgOOPP56KigpGjhwJwHXXXceTTz7Jtm3b+NznPsedd97Z7C06B45GFHuPN/W/BTNrGmeddRZnnXVW3fqkSZN48MEHGTp0KG+99VaD5caNG8emTZv4yU9+skP6BRdcwAMPPADA+eefz+TJk7niiisYN24c48aNA+CJJ55g4sSJHHjggdTW1jJmzBieeeYZSktLOfbYYznjjDMYOHAgv/rVr+r2e8455zBixIi69draWr7xjW9w2mmn1aU9//zz/OY3v2HJkiUAnHjiicybN49TTjll9y/QbnBXlZl1GK+//jq33HIL06dPp1OnTpSUlHDggQcWzDtkyBD22WefndKHDx+OJCQxePBgqqqqdsozY8YMzjvvPADmz59P//79Oeyww+jatSujR4/m8ccf3yH/xo0bmTt3LmeeeWZd2g9/+EPOOeccPvKRj9SlSWLz5s1s2bKFDz74gK1bt3LwwQfvzqXYIw4cZtYhbN26lfPPP5877riDQw45BIC+ffvy6KOP7vb+pk+fzrBhw3ZI37RpE0899RTnnHMOAGvWrKFv375120tLS1mzZs0OZR577DGGDBnCvvvuW1dm1qxZXHHFFTvkO/744zn11FPp1asXvXr1YujQoRx++OG7Vf894cBhZh3CN7/5TQYNGsSoUaOaZH9XXnklJ598MieddNIO6U888QSf+cxnGmzJFJLfQgG4+uqrmTBhAp067fgreuXKlSxfvpyqqirWrFnD3Llzd+juai4e4zCzdu+5557jkUce4aWXXmqS/d18881UV1fvNP4BUFFRsUMQ6NOnD6tXr65br6qqok+fPnXr7777LvPnz2fWrFl1aZWVlYwePbpu+5w5c+jcuTMrVqzguOOOY++99wbg9NNP54UXXtgpeGXNLQ4za9fWr1/PxRdfzLRp0wqOWaQ1efJknn76aWbMmLFTi2DDhg3Mmzdvh0HuY489lhUrVrBq1Sq2bNlCRUUFZ5xxRt32mTNn8vnPf57u3bvXpa1atYo333yTN998k5EjR/KjH/2IM888k0MOOYR58+ZRU1PD1q1bmTdvXot0VbnFYWbNq5kfQfzxj3/M2rVrdxovuOGGG3bZbXXSSSfx6quv8t5771FaWsqUKVMYOnQoX/3qVzn00EM5/vjjATj77LP51re+BeQe/T3ttNP48Ic/XLefzp07c9dddzF06FBqa2u55JJLGDRoUN32ioqKusdzGzNy5Ejmzp3LkUceiSSGDRvGF77whaKvRVNRRDT7QZtbeXl57O6HnPw4rtmeWb58eYv8VWzpFPr/JGlhRJTXz+uuKjMzS8WBw8zMUnHgMDOzVBw4zMwsFQcOMzNLxYHDzMxSyfQ9DknDgDuBEmByRNxeb3s3YBpwDLAOGBURb0rqAcwEjgWmRsTYJP9ewP8CHwVqgSciorgHoM2sVWjmWdWB3NvaY8aMYdmyZdTW1jJ8+HDuuOMOunXrBuQmIrz22mt555132GuvvTjmmGP4wQ9+wMMPP8y4ceMoLS3lvffe47DDDuOmm27ihBNO2OkYv/zlL7n66qtZsmTJDtOgQ8NTtD/77LOMGzeObdu2sffeezN16lT69+/PW2+9xYUXXshf/vIXamtruf322xk+fDhbtmzhK1/5CpWVlXTq1Ik777yzbmbcGTNmcNtttyGJ3r1788ADD3DQQQcxfvx47r33Xnr27AnAbbfdxvDhw3f/gpNhi0NSCXA3cDowEDhP0sB62S4F1kdEf2AiMCFJ3wx8E7i2wK7/KyL+AfgU8BlJp2dRfzNrHyKCs88+mzPPPJMVK1awYsUK/va3v3HdddcB8M477/DFL36RCRMm8Nprr7Fo0SKGDRtW952MUaNGsWjRIlasWMH111/P2WefzfLly3c6ziGHHMLUqVM5//zzd9o2btw4pk+fvlP6FVdcwYMPPsjixYs5//zzufXWWwG49dZbOffcc1m0aBEVFRVceeWVANx7770AvPzyyzzzzDNcc801bNu2jZqaGq666ip+8YtfsGTJEo466ijuuuuuuuN87WtfY/HixSxevHiPgwZk21U1GFgZEW9ExBagAhhRL88I4P5keSYwRJIi4v2I+DW5AFInIjZFxC+S5S3AS0BphudgZm3c3Llz6d69OxdffDEAJSUlTJw4kWnTpvHee+9x9913c+GFF9a9CQ65N7QLTVd+6qmncvnllzNp0qSdtpWVlXHUUUftNA0JNDxFuyQ2btwI5KYr6d279y7Tly1bxmc/+1kAPvKRj7D//vtTWVlJRBARvP/++0QEGzdurCuThSwDRx9gdd56VZJWME9E1AAbgB7F7FzS/sAXgGcb2H65pEpJldXV1elqbmbtxtKlSznmmGN2SNt3330pKytj5cqVvPLKKztt35Wjjz6aV199tUnqNnnyZIYPH05paSnTp0+vm3pk/PjxPPDAA5SWljJ8+HB++MMfAvCJT3yC2bNnU1NTw6pVq1i4cCGrV6+mS5cu3HPPPRx55JH07t2bZcuWcemll9Yd56677uKoo47ikksuYf369Xtc7zY5OC6pMzAD+EFEvFEoT0RMiojyiCjf3rdnZranmnKapokTJzJnzhyqqqq4+OKL+frXvw7kxisuuugiqqqqmDNnDl/60pfYtm0bl1xyCaWlpZSXl3P11VdzwgknUFJSwtatW7nnnntYtGgRf/zjHznqqKP4zne+A+S6w37/+9+zePFievXqxTXXXLPH9c4ycKwB+uatlyZpBfMkwWA/coPkjZkErIiI7+95Nc2sPRs4cCALFy7cIW3jxo386U9/4uMf/ziDBg3aafuuLFq0qEnm3qquruZ3v/sdn/70p4HcWMrzzz8PwJQpUzj33HOB3MebNm/ezLvvvkvnzp2ZOHEiixcv5vHHH+cvf/kLH/vYx1i8eDEAH/3oR5HEueeeW7evgw8+mJKSEjp16sRll13G/Pnz97juWQaOBcAASf0kdQVGA7Pr5ZkNXJgsjwTmRiPhXNKt5ALM1U1bXTNrj4YMGcKmTZuYNm0akPuW9zXXXMPYsWP50Ic+xNixY7n//vt58cUX68o8+uijvPPOOzvta968eUyaNInLLrtsj+t1wAEHsGHDBl5//XUAnnnmmbqAdMghh/Dss7le+OXLl7N582Z69uzJpk2beP/99+vyd+7cmYEDB9KnTx+WLVvG9m75/H29/fbbdcecNWsWRxxxxB7XPbPHcSOiRtJY4Glyj+PeFxFLJd0CVEbEbGAKMF3SSuDP5IILAJLeBPYFuko6EzgN2AjcCLwKvCQJ4K6ImJzVeZhZ02rumaQlMWvWLMaMGcO3v/1tqqurGTVqFDfeeCOQ+4u8oqKCa6+9lrVr19KpUydOPvnkuk/CPvTQQ/z6179m06ZN9OvXj0ceeaRgi2PBggWcddZZrF+/nieeeIKbbrqJpUuXAg1P0X7vvfdyzjnn0KlTJw444ADuu+8+AO644w4uu+wyJk6ciCSmTp2KJNauXcvQoUPp1KkTffr0qXtSq3fv3tx0002cfPLJdOnShUMPPZSpU6cCcN1117F48WIkUVZWVvDjU6mvqadV3zVPq262Z1rbtOrPP/885513HrNmzeLoo49u6eq0GmmmVfeHnMysQznhhBP4wx/+0NLVaNPa5FNVZmbWchw4zCxzHaFLvC1L+//HgcPMMtW9e3fWrVvn4NFKRQTr1q2je/fuRZfxGIeZZaq0tJSqqio8g0Pr1b17d0pLi5+9yYHDzDLVpUsX+vXr19LVsCbkriozM0vFgcPMzFJx4DAzs1QcOMzMLBUHDjMzS8WBw8zMUnHgMDOzVPweRxNJMzuuZ9I1s7bMLQ4zM0vFgcPMzFJx4DAzs1QcOMzMLBUHDjMzS8WBw8zMUnHgMDOzVBw4zMwsFQcOMzNLJdPAIWmYpNckrZR0fYHt3SQ9lGx/UVJZkt5D0i8kvSfprnpljpH0clLmB5KU5TmYmdmOMgsckkqAu4HTgYHAeZIG1st2KbA+IvoDE4EJSfpm4JvAtQV2fQ9wGTAg+RnW9LU3M7OGZNniGAysjIg3ImILUAGMqJdnBHB/sjwTGCJJEfF+RPyaXACpI6kXsG9E/DYiApgGnJnhOZiZWT1ZBo4+wOq89aokrWCeiKgBNgA9GtlnVSP7BEDS5ZIqJVVWV1enrLqZmTWk3Q6OR8SkiCiPiPKePXu2dHXMzNqNLAPHGqBv3nppklYwj6TOwH7Aukb2WdrIPs3MLENZBo4FwABJ/SR1BUYDs+vlmQ1cmCyPBOYmYxcFRcTbwEZJxyVPU/0z8HjTV93MzBqS2YecIqJG0ljgaaAEuC8ilkq6BaiMiNnAFGC6pJXAn8kFFwAkvQnsC3SVdCZwWkQsA64EpgIfAn6W/JiZWTPJ9AuAETEHmFMv7Vt5y5uBLzZQtqyB9ErgiKarpZmZpdFuB8fNzCwbDhxmZpaKA4eZmaXiwGFmZqk4cJiZWSqZPlVlhY0f37T5zMyak1scZmaWigOHmZml4sBhZmapOHCYmVkqDhxmZpaKA4eZmaXiwGFmZqk4cJiZWSoOHGZmlooDh5mZpeLAYWZmqThwmJlZKg4cZmaWigOHmZml4sBhZmap+HscrVia73H42x1m1lwybXFIGibpNUkrJV1fYHs3SQ8l21+UVJa37YYk/TVJQ/PSvyZpqaRXJM2Q1D3LczAzsx1lFjgklQB3A6cDA4HzJA2sl+1SYH1E9AcmAhOSsgOB0cAgYBjwI0klkvoA/wqUR8QRQEmSz8zMmkmWLY7BwMqIeCMitgAVwIh6eUYA9yfLM4EhkpSkV0TEBxGxCliZ7A9y3WsfktQZ2Av4Y4bnYGZm9WQZOPoAq/PWq5K0gnkiogbYAPRoqGxErAH+C3gLeBvYEBH/V+jgki6XVCmpsrq6uglOx8zMoI09VSXpAHKtkX5Ab+DDkv6pUN6ImBQR5RFR3rNnz+aspplZu5Zl4FgD9M1bL03SCuZJup72A9btouw/AqsiojoitgKPAidkUnszMysodeCQdICko4rIugAYIKmfpK7kBrFn18szG7gwWR4JzI2ISNJHJ09d9QMGAPPJdVEdJ2mvZCxkCLA87TmYmdnuK+o9DknPAWck+RcCayX9JiK+3lCZiKiRNBZ4mtzTT/dFxFJJtwCVETEbmAJMl7QS+DPJE1JJvoeBZUANMCYiaoEXJc0EXkrSFwGTduO8zcxsNxX7AuB+EbFR0peBaRFxk6QljRWKiDnAnHpp38pb3gx8sYGy/wH8R4H0m4Cbiqy3mZk1sWK7qjpL6gWcC/w0w/qYmVkrV2zguJlcl9PKiFgg6TBgRXbVMjOz1qrYrqq3I6JuQDwi3pD0vYzqZLuh2LmqPKeVme2pYlscPywyzczM2rldtjgkHU/uPYmekvKfoNqX3JNSZmbWwTTWVdUV2DvJt09e+kZy712YmVkHs8vAERHzgHmSpkbEH5qpTmZm1ooVOzjeTdIkoCy/TER8NotKmZlZ61Vs4Phf4MfAZKA2u+qYmVlrV2zgqImIezKtiZmZtQnFPo77hKQrJfWSdOD2n0xrZmZmrVKxLY7tM9iOy0sL4LCmrY5lLc0LgH5Z0MwKKSpwRES/rCtiZmZtQ7HTqv9zofSImNa01TEzs9au2K6qY/OWu5P7gNJLgAOHmVkHU2xX1b/kr0vaH6jIokJmZta67e43x98HPO5hZtYBFTvG8QS5p6ggN7nh4cDDWVXKzMxar2LHOP4rb7kG+ENEVGVQH2tF/I0PMyukqK6qZLLDV8nNkHsAsCXLSpmZWetVVOCQdC4wH/giue+OvyjJ06qbmXVAxXZV3QgcGxFrAST1BH4OzMyqYmZm1joV+1RVp+1BI7EuRVkzM2tHiv3l/5SkpyVdJOki4ElgTmOFJA2T9JqklZKuL7C9m6SHku0vSirL23ZDkv6apKF56ftLminpVUnLk8/bmplZM2nsm+P9gYMjYpyks4ETk00vAA82UrYEuBv4HFAFLJA0OyKW5WW7FFgfEf0ljQYmAKMkDQRGA4OA3sDPJX0sImqBO4GnImKkpK7AXinP2czM9kBjYxzfB24AiIhHgUcBJB2ZbPvCLsoOBlZGxBtJmQpgBJAfOEYA45PlmcBdkpSkV0TEB8AqSSuBwZKWAScDFyV12oKf8GpxnnHXrGNprKvq4Ih4uX5iklbWSNk+wOq89aokrWCeiKgBNgA9dlG2H1AN/LekRZImS/pwoYNLulxSpaTK6urqRqpqZmbFaixw7L+LbR9qwnoUqzNwNHBPRHyK3NQnO42dAETEpIgoj4jynj17Nmcdzczatca6qiolXRYR9+YnSvoysLCRsmuAvnnrpUlaoTxVkjoD+5F7YquhslVAVUS8mKTPpIHA0ao991xx+U45pWX3mQG/jW7W9jUWOK4GZkm6gL8HinKgK3BWI2UXAAMk9SP3S380cH69PLPJfV3wBWAkMDciQtJs4H8kfY/c4PgAYH5E1EpaLenjEfEauendl9EaFPuLu6X3aWa2h3YZOCLiHeAESacCRyTJT0bE3MZ2HBE1ksYCT5ObGPG+iFgq6RagMiJmA1OA6cng95/JBReSfA+TCwo1wJjkiSqAfwEeTJ6oegO4ON0pp+Rf3mZmO1BENJ6rjSsvL4/KysrdKjv+lOeatjJtSQt2a7mryqzlSVoYEeX10/32t5mZpVLsXFXWEbXggLvfDTFrvdziMDOzVBw4zMwsFXdV2Z5L8+RZC79HYmZ7zoHDmlcG4yZ+qdCsebmryszMUnGLw1ond3+ZtVoOHNb2FR1kTsmwEmYdhwOHdRx+OcSsSThwWIcx/rlTis/rEXezBjlwmO0Jt2KsA3LgMGsuWQQOByNrAQ4cZgUU263V4rMnu0vNWoADh1lH4C41a0IOHGa2I7dirBF+c9zMzFJxi8NsD6R6xLelx0Oamru/Oiy3OMzMLBW3OMwsex43aVfc4jAzs1QcOMzMLJVMu6okDQPuBEqAyRFxe73t3YBpwDHAOmBURLyZbLsBuBSoBf41Ip7OK1cCVAJrIuLzWZ6DmTUjD7i3CZkFjuSX+93A54AqYIGk2RGxLC/bpcD6iOgvaTQwARglaSAwGhgE9AZ+LuljEVGblLsKWA7sm1X9zZpam3kb3awRWXZVDQZWRsQbEbEFqABG1MszArg/WZ4JDJGkJL0iIj6IiFXAymR/SCoF/h8wOcO6m5lZA7LsquoDrM5brwI+3VCeiKiRtAHokaT/tl7ZPsny94HrgH2avspmLa9DvxuShp/UajFtanBc0ueBtRGxsIi8l0uqlFRZXV3dDLUzM+sYsmxxrAH65q2XJmmF8lRJ6gzsR26QvKGyZwBnSBoOdAf2lfRARPxT/YNHxCRgEkB5eXk0yRmZWdvjAfcml2WLYwEwQFI/SV3JDXbPrpdnNnBhsjwSmBsRkaSPltRNUj9gADA/Im6IiNKIKEv2N7dQ0DAzs+xk1uJIxizGAk+Texz3vohYKukWoDIiZgNTgOmSVgJ/JhcMSPI9DCwDaoAxeU9UmZlZC1LuD/z2rby8PCorK3erbIcefLR2w/dxE+sgXVqSFkZEef30NjU4bmZmLc+Bw8zMUvHsuGZmaXXwJ7UcOMw6AL9UaE3JgcPMLEvt8A13j3GYmVkqDhxmZpaKu6rMbAee/r2FtKEBd7c4zMwsFQcOMzNLxV1VZmZtTQs/qeXAYWa7xe+GdFzuqjIzs1QcOMzMLBV3VZlZ5vyIb/viFoeZmaXiwGFmZqk4cJiZWSoOHGZmlooHx82s1fC7IW2DWxxmZpaKA4eZmaXiwGFmZqlkOsYhaRhwJ1ACTI6I2+tt7wZMA44B1gGjIuLNZNsNwKVALfCvEfG0pL5J/oOBACZFxJ1ZnoOZtU5+qbDlZNbikFQC3A2cDgwEzpM0sF62S4H1EdEfmAhMSMoOBEYDg4BhwI+S/dUA10TEQOA4YEyBfZqZWYaybHEMBlZGxBsAkiqAEcCyvDwjgPHJ8kzgLklK0isi4gNglaSVwOCIeAF4GyAi/ippOdCn3j7NzOr4Sa2ml+UYRx9gdd56VZJWME9E1AAbgB7FlJVUBnwKeLHQwSVdLqlSUmV1dfXun4WZme2gTQ6OS9obeAS4OiI2FsoTEZMiojwiynv27Nm8FTQza8ey7KpaA/TNWy9N0grlqZLUGdiP3CB5g2UldSEXNB6MiEezqbqZdUQecC9Oli2OBcAASf0kdSU32D27Xp7ZwIXJ8khgbkREkj5aUjdJ/YABwPxk/GMKsDwivpdh3c3MrAGZtTgiokbSWOBpco/j3hcRSyXdAlRGxGxyQWB6Mvj9Z3LBhSTfw+QGvWuAMRFRK+lE4EvAy5IWJ4f6t4iYk9V5mJnZjpT7A799Ky8vj8rKyt0q29GbpGa2Z1r0d8j48XtUXNLCiCivn94mB8fNzKzlOHCYmVkqnlbdzCxD7fFJLbc4zMwsFbc4zMxagbY0NYpbHGZmlopbHGZmbUzR4yYZHd8tDjMzS8WBw8zMUnHgMDOzVBw4zMwsFQcOMzNLxYHDzMxSceAwM7NUHDjMzCwVBw4zM0vFgcPMzFJx4DAzs1QcOMzMLBUHDjMzS8WBw8zMUnHgMDOzVBw4zMwslUwDh6Rhkl6TtFLS9QW2d5P0ULL9RUlledtuSNJfkzS02H2amVm2MgsckkqAu4HTgYHAeZIG1st2KbA+IvoDE4EJSdmBwGhgEDAM+JGkkiL3aWZmGcqyxTEYWBkRb0TEFqACGFEvzwjg/mR5JjBEkpL0ioj4ICJWASuT/RWzTzMzy1CW3xzvA6zOW68CPt1QnoiokbQB6JGk/7Ze2T7JcmP7BEDS5cDlyep7kl7bjXPYEwcB7zbzMdsaX6Nd8/VpnK/RLtysPb4+hxZKzDJwtKiImARMaqnjS6qMiPKWOn5b4Gu0a74+jfM12rWsrk+WXVVrgL5566VJWsE8kjoD+wHrdlG2mH2amVmGsgwcC4ABkvpJ6kpusHt2vTyzgQuT5ZHA3IiIJH108tRVP2AAML/IfZqZWYYy66pKxizGAk8DJcB9EbFU0i1AZUTMBqYA0yWtBP5MLhCQ5HsYWAbUAGMiohag0D6zOoc91GLdZG2Ir9Gu+fo0ztdo1zK5Psr9gW9mZlYcvzluZmapOHCYmVkqDhxNRNKbkl6WtFhSZZJ2oKRnJK1I/ntAS9ezOUm6T9JaSa/kpRW8Jsr5QTKVzBJJR7dczZtHA9dnvKQ1yX20WNLwvG0Fp+FpryT1lfQLScskLZV0VZLueyixi2uU7X0UEf5pgh/gTeCgemn/CVyfLF8PTGjpejbzNTkZOBp4pbFrAgwHfgYIOA54saXr30LXZzxwbYG8A4HfAd2AfsDvgZKWPoeMr08v4OhkeR/g9eQ6+B5q/Bpleh+5xZGt/ClV7gfObLmqNL+I+CW5p+XyNXRNRgDTIue3wP6SejVLRVtIA9enIQ1Nw9NuRcTbEfFSsvxXYDm5GSR8DyV2cY0a0iT3kQNH0wng/yQtTKY7ATg4It5Olv8EHNwyVWtVGromhaao2dU/gPZsbNLVcl9e92aHvj7JzNmfAl7E91BB9a4RZHgfOXA0nRMj4mhyM/eOkXRy/sbItRP97HMeX5OC7gE+CnwSeBu4o0Vr0wpI2ht4BLg6Ijbmb/M9lFPgGmV6HzlwNJGIWJP8dy0wi1zz753tTeXkv2tbroatRkPXxNPJABHxTkTURsQ24F7+3o3QIa+PpC7kfiE+GBGPJsm+h/IUukZZ30cOHE1A0ocl7bN9GTgNeIUdp1S5EHi8ZWrYqjR0TWYD/5w8GXMcsCGvO6LDqNcnfxa5+wganoan3Uo+sTAFWB4R38vb5Hso0dA1yvw+aumnAtrDD3AYuScVfgcsBW5M0nsAzwIrgJ8DB7Z0XZv5uswg10zeSq4v9dKGrgm5J2HuJveUx8tAeUvXv4Wuz/Tk/Jck/8h75eW/Mbk+rwGnt3T9m+H6nEiuG2oJsDj5Ge57qKhrlOl95ClHzMwsFXdVmZlZKg4cZmaWigOHmZml4sBhZmapOHCYmVkqDhzWYUh6bxfb9pd0ZXPWpxiSvr99FgJJnSXdlswKu33W0xsbKf/fkr5SL+1MST+T1FXSLyV1TtJ7Snoqu7Ox9sKBwyxnf6BVBQ5JPYDjIjcZIsCtQG/gyIj4JHAS0KWR3cwg+SRzntHAjIjYQu59iFEAEVENvC3pM01zBtZeOXBYhyNpnKQFyQRwNyfJtwMfTf6K/269/GWSXpU0VdLrkh6U9I+SfpP89T84yTdY0guSFkl6XtLHk/RBkuYn+14iaUAy28CTkn4n6RVJowpU9RzgqWQfewGXAf8SEZshNxtqRIzPq+c/5R3nJ5JKyAWGf8ibouPDwD8CjyXFHgMuyDtm/XWznThwWIci6TRy0ywMJjcB3DFJV9D1wO8j4pMRMa5A0f7kJor7h+TnfHJv7V4L/FuS51XgpIj4FPAt4LYk/avAnUkroZzcW+LDgD9GxCci4giSAFHPZ4CFecd/K3JTZxc6r8PJtRw+kxynFrggImrJzWN0bpL1C8Bz8ffJAl8Bjs3bVSW5loxZgxw4rKM5LflZBLxELggMKKLcqoh4OXKTxi0Fno3ctAsvA2VJnv2A/1Xui34TgUFJ+gvAv0n6BnBoRPwtKfc5SRMknRQRGwocsxdQXagyki5OWharJfUFhgDHAAskLU7WD0uy53dXjU7WAUgCy5btc62RmzCwdxHXwzowBw7raAR8J2lZfDIi+kfElCLKfZC3vC1vfRvQOVn+NvCLpAXxBaA7QET8D3AG8DdgjqTPRsTr5L7+9zJwq6RvFTjm37bvg9wHdw7Z/gs+Iv47aVlsAEqS87o/77w+nteN9TzQS9IngBOAJ+sdpxuwOVnunhzXrEEOHNbRPA1ckny/AEl9JH0E+Cu5T2/uif34+xTVF21PlHQY8EZE/IDcTK5HSeoNbIqIB4Dvkgsi9S0n10VFRGwiNwvqXZK6J/stAbomeZ8FRibnsv273IcmZQN4iNzX8n62fYwkydcDeDcitiZJH+PvM6maFeTAYR1C8sjpBxHxf8D/AC9IehmYCewTEeuA3yQD1d/d1b524T+B70haxN9bIZAbX3gl6UI6ApgGHAnMT9JuIvfEVH1PAqfkrd9IbjbdV5Jj/IpcMPhjRCwD/p3cVyiXAM+Q6+rabgbwCfK6qRKnsmMLpP662U48O651CEk3zb0R0aa+0y3p18DnI+IvGe3/UeD6pOsMSb8ERkTE+iyOZ+2DWxzW7kn6Krm/tP+9peuyG64BDslix5K6Ao/lBY2ewPccNKwxbnGYmVkqbnGYmVkqDhxmZpaKA4eZmaXiwGFmZqk4cJiZWSr/H/Xt5/CYm20GAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creates Training Data\n",
    "\n",
    "# Opens files and reads data\n",
    "\n",
    "print(\"Extracting\")\n",
    "n_encoded_nodes = 2\n",
    "weightClr = 1\n",
    "weightCorr1 = 1\n",
    "weightCorr2 = 0\n",
    "msd_sig_min = 40.\n",
    "msd_sig_max = 250.\n",
    "loss_text=\"%iD encoder, $\\lambda_{CLR}$=%i, $\\lambda_{corr1}$=%i, $\\lambda_{corr2}$=%i\"%(n_encoded_nodes, weightClr, weightCorr1, weightCorr2)\n",
    "\n",
    "label=f'contrastiveBarlow_{n_encoded_nodes}_dimensions_{weightClr}Clr_{weightCorr1}Corr1_{weightCorr2}Corr2_{msd_sig_min}sigMassMin_{msd_sig_max}sigMassMax'\n",
    "outdir = '/uscms_data/d3/jkrupa/flat/FlatSamples/plots/'+label\n",
    "os.system(f'mkdir -p {outdir}')\n",
    "fOne = h5py.File(\"/uscms_data/d3/eamoreno/FlatSamples/data/FullQCD_FullSig_Zqq_noFill_dRlimit08_50particlesordered_genMatched50.h5\", 'r')\n",
    "totalData = fOne[\"deepDoubleQ\"][:]\n",
    "print(totalData.shape)\n",
    "\n",
    "print(\"Preparing Data\")\n",
    "\n",
    "particleDataLength = particlesConsidered * entriesPerParticle\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(totalData)\n",
    "\n",
    "#trainingDataLength = int(datapoints*0.8)\n",
    "#validationDataLength = int(datapoints*0.1)\n",
    "\n",
    "mask = [i>40 for i in totalData[:, eventDataLength-1]]\n",
    "mask2 = []\n",
    "for i in range(totalData.shape[0]):\n",
    "    if totalData[i,-1]==0:\n",
    "        mask2.append(True)\n",
    "    else:\n",
    "        mass = totalData[i,eventDataLength-1]\n",
    "        if (mass > msd_sig_min) and (mass < msd_sig_max):\n",
    "            mask2.append(True)\n",
    "        else:\n",
    "            mask2.append(False)\n",
    "            \n",
    "tot_mask = mask and mask2\n",
    "print(totalData.shape)\n",
    "print(len(tot_mask), tot_mask[-100:])\n",
    "print(len(mask), mask[-100:])\n",
    "print(len(mask2), mask2[-100:])\n",
    "\n",
    "totalData = totalData[tot_mask]\n",
    "datapoints = min(sum(totalData[:,-1]==1), sum(totalData[:,-1]==0))\n",
    "print(\"datapoints\",datapoints)\n",
    "trainingDataLength = int(len(totalData)*0.8)\n",
    "validationDataLength = int(len(totalData)*0.1)\n",
    "print(totalData)\n",
    "labels = totalData[:, decayTypeColumn:]\n",
    "particleData = totalData[:, eventDataLength:particleDataLength + eventDataLength]\n",
    "eventData = totalData[:, :eventDataLength]\n",
    "jetMassData = totalData[:, eventDataLength-1] #last entry in eventData (zero indexing)\n",
    "\n",
    "\n",
    "######### Training Data ###############\n",
    "eventTrainingData = np.array(eventData[0:trainingDataLength],dtype=np.float16)\n",
    "jetMassTrainingData = np.array(jetMassData[0:trainingDataLength],dtype=np.float16)\n",
    "particleTrainingData = np.transpose(\n",
    "    particleData[0:trainingDataLength, ].reshape(trainingDataLength, \n",
    "                                                 entriesPerParticle, \n",
    "                                                 particlesConsidered),\n",
    "                                                 axes=(0, 1, 2))\n",
    "particleTrainingData = particleTrainingData.astype(np.float16)\n",
    "\n",
    "trainingLabels = np.array([[i, 1-i] for i in labels[0:trainingDataLength]]).reshape((-1, 2))\n",
    "\n",
    "torch.save(torch.Tensor(particleTrainingData),f\"{outdir}/{label}_particleTrainingData.pt\")\n",
    "torch.save(torch.Tensor(jetMassTrainingData),f\"{outdir}/{label}_jetMassTrainingData.pt\")\n",
    "torch.save(torch.Tensor(trainingLabels),f\"{outdir}/{label}_trainingLabels.pt\")\n",
    "\n",
    "\n",
    "########## Validation Data ##########\n",
    "eventValidationData = np.array(eventData[trainingDataLength:trainingDataLength + validationDataLength])\n",
    "jetMassValidationData = np.array(jetMassData[trainingDataLength:trainingDataLength + validationDataLength])\n",
    "particleValidationData = np.transpose(\n",
    "    particleData[trainingDataLength:trainingDataLength + validationDataLength, ].reshape(validationDataLength,\n",
    "                                                                                         entriesPerParticle,\n",
    "                                                                                         particlesConsidered),\n",
    "                                                                                         axes=(0, 1, 2))\n",
    "validationLabels = np.array([[i, 1-i] for i in labels[trainingDataLength:trainingDataLength + validationDataLength]]).reshape((-1, 2))\n",
    "\n",
    "\n",
    "\n",
    "########### Testing Data ############\n",
    "particleTestData = np.transpose(particleData[trainingDataLength + validationDataLength:,].reshape(\n",
    "    len(particleData) - trainingDataLength - validationDataLength, entriesPerParticle, particlesConsidered),\n",
    "                                axes=(0, 1, 2))\n",
    "testLabels = np.array(labels[trainingDataLength + validationDataLength:])\n",
    "\n",
    "print('Selecting particlesPostCut')\n",
    "particleTrainingData = particleTrainingData[:, :particlesPostCut]\n",
    "particleValidationData = particleValidationData[:, :particlesPostCut]\n",
    "\n",
    "particlesConsidered = particlesPostCut\n",
    "\n",
    "# Separating signal and bkg arrays\n",
    "particleTrainingDataSig = particleTrainingData[trainingLabels[:,0].astype(bool)]\n",
    "particleTrainingDataBkg = particleTrainingData[trainingLabels[:,1].astype(bool)]\n",
    "particleValidationDataSig = particleValidationData[validationLabels[:,0].astype(bool)]\n",
    "particleValidationDataBkg = particleValidationData[validationLabels[:,1].astype(bool)]\n",
    "particleTrainingLabelSig = trainingLabels[trainingLabels[:,0].astype(bool)]\n",
    "particleTrainingLabelBkg = trainingLabels[trainingLabels[:,1].astype(bool)]\n",
    "\n",
    "# Jet mass for correlation\n",
    "jetMassTrainingDataSig = jetMassTrainingData[trainingLabels[:,0].astype(bool)]\n",
    "jetMassTrainingDataBkg = jetMassTrainingData[trainingLabels[:,1].astype(bool)]\n",
    "jetMassValidationDataSig = jetMassValidationData[validationLabels[:,0].astype(bool)]\n",
    "jetMassValidationDataBkg = jetMassValidationData[validationLabels[:,1].astype(bool)]\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.hist(jetMassTrainingDataSig,color=\"r\",bins=np.linspace(40,250,30),alpha=0.5,label=f\"Z' {len(jetMassTrainingDataSig)}\",density=True)\n",
    "ax.hist(jetMassTrainingDataBkg,color=\"b\",bins=np.linspace(40,250,30),alpha=0.5,label=f\"QCD {len(jetMassTrainingDataBkg)}\",density=True)\n",
    "plt.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"Jet mass (GeV))\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "plt.savefig(outdir+\"/massHist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4103a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the interaction matrices\n",
    "class GraphNetnoSV(nn.Module):\n",
    "    def __init__(self, n_constituents, n_targets, params, hidden, De=5, Do=6, softmax=False):\n",
    "        super(GraphNetnoSV, self).__init__()\n",
    "        self.hidden = int(hidden)\n",
    "        self.P = params\n",
    "        self.Nv = 0 \n",
    "        self.N = n_constituents\n",
    "        self.Nr = self.N * (self.N - 1)\n",
    "        self.Nt = self.N * self.Nv\n",
    "        self.Ns = self.Nv * (self.Nv - 1)\n",
    "        self.Dr = 0\n",
    "        self.De = De\n",
    "        self.Dx = 0\n",
    "        self.Do = Do\n",
    "        self.S = 0\n",
    "        self.n_targets = n_targets\n",
    "        self.assign_matrices()\n",
    "           \n",
    "        self.Ra = torch.ones(self.Dr, self.Nr)\n",
    "        self.fr1 = nn.Linear(2 * self.P + self.Dr, self.hidden).cuda()\n",
    "        self.fr2 = nn.Linear(self.hidden, int(self.hidden/2)).cuda()\n",
    "        self.fr3 = nn.Linear(int(self.hidden/2), self.De).cuda()\n",
    "        self.fr1_pv = nn.Linear(self.S + self.P + self.Dr, self.hidden).cuda()\n",
    "        self.fr2_pv = nn.Linear(self.hidden, int(self.hidden/2)).cuda()\n",
    "        self.fr3_pv = nn.Linear(int(self.hidden/2), self.De).cuda()\n",
    "        \n",
    "        self.fo1 = nn.Linear(self.P + self.Dx + (self.De), self.hidden).cuda()\n",
    "        self.fo2 = nn.Linear(self.hidden, int(self.hidden/2)).cuda()\n",
    "        self.fo3 = nn.Linear(int(self.hidden/2), self.Do).cuda()\n",
    "        \n",
    "        self.fc_fixed = nn.Linear(self.Do, self.n_targets).cuda()\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "            \n",
    "    def assign_matrices(self):\n",
    "        self.Rr = torch.zeros(self.N, self.Nr)\n",
    "        self.Rs = torch.zeros(self.N, self.Nr)\n",
    "        receiver_sender_list = [i for i in itertools.product(range(self.N), range(self.N)) if i[0]!=i[1]]\n",
    "        for i, (r, s) in enumerate(receiver_sender_list):\n",
    "            self.Rr[r, i] = 1\n",
    "            self.Rs[s, i] = 1\n",
    "        self.Rr = (self.Rr).cuda()\n",
    "        self.Rs = (self.Rs).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ###PF Candidate - PF Candidate###\n",
    "        Orr = self.tmul(x, self.Rr)\n",
    "        Ors = self.tmul(x, self.Rs)\n",
    "        B = torch.cat([Orr, Ors], 1)\n",
    "        ### First MLP ###\n",
    "        B = torch.transpose(B, 1, 2).contiguous()\n",
    "        B = nn.functional.relu(self.fr1(B.view(-1, 2 * self.P + self.Dr)))\n",
    "        B = nn.functional.relu(self.fr2(B))\n",
    "        E = nn.functional.relu(self.fr3(B).view(-1, self.Nr, self.De))\n",
    "        del B\n",
    "        E = torch.transpose(E, 1, 2).contiguous()\n",
    "        Ebar_pp = self.tmul(E, torch.transpose(self.Rr, 0, 1).contiguous())\n",
    "        del E\n",
    "        \n",
    "\n",
    "        ####Final output matrix for particles###\n",
    "        \n",
    "\n",
    "        C = torch.cat([x, Ebar_pp], 1)\n",
    "        del Ebar_pp\n",
    "        C = torch.transpose(C, 1, 2).contiguous()\n",
    "        ### Second MLP ###\n",
    "        C = nn.functional.relu(self.fo1(C.view(-1, self.P + self.Dx + (self.De))))\n",
    "        C = nn.functional.relu(self.fo2(C))\n",
    "        O = nn.functional.relu(self.fo3(C).view(-1, self.N, self.Do))\n",
    "        del C\n",
    "\n",
    "        \n",
    "        #Taking the sum of over each particle/vertex\n",
    "        N = torch.sum(O, dim=1)\n",
    "        del O\n",
    "        \n",
    "        ### Classification MLP ###\n",
    "\n",
    "        N = self.fc_fixed(N)\n",
    "        \n",
    "        if softmax:\n",
    "            N = nn.Softmax(dim=1)(N)\n",
    "        \n",
    "        return self.activation(N)\n",
    "            \n",
    "    def tmul(self, x, y):  #Takes (I * J * K)(K * L) -> I * J * L \n",
    "        x_shape = x.size()\n",
    "        y_shape = y.size()\n",
    "        return torch.mm(x.view(-1, x_shape[2]), y).view(-1, x_shape[1], y_shape[1])\n",
    "    \n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, n_targets):\n",
    "        super(DNN, self).__init__()\n",
    "        #self.flat = torch.flatten()\n",
    "        self.f0 = nn.Linear(200, 400).cuda()\n",
    "        self.f0b = nn.Linear(400, 400).cuda()\n",
    "        self.f1 = nn.Linear(400, 100).cuda()\n",
    "        self.f2 = nn.Linear(100, 50).cuda()\n",
    "        self.f3 = nn.Linear(50, 10).cuda()\n",
    "        self.f4 = nn.Linear(10, n_targets).cuda()\n",
    "        self.activation = torch.nn.ReLU()\n",
    "    def forward(self, x): \n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "        x = self.activation(self.f0(x))\n",
    "        #x = self.f0b(x)\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.f4(x)\n",
    "        return(x)\n",
    "    \n",
    "\n",
    "class simple_MLP(torch.nn.Module):\n",
    "    def __init__(self,input_size=5,out_channels=2,act_out=True,nlayers=4,nhidden=50,batchnorm=True):\n",
    "        super().__init__()\n",
    "        self.bn  = torch.nn.BatchNorm1d(input_size).cuda()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 50, bias=False).cuda()\n",
    "        self.ac1 = torch.nn.ReLU().cuda()\n",
    "        self.dp1 = torch.nn.Dropout(p=0.2).cuda()\n",
    "        self.fc2 = torch.nn.Linear(50, 30).cuda()\n",
    "        self.ac2 = torch.nn.ReLU().cuda()\n",
    "        self.fc3 = torch.nn.Linear(30, 10).cuda()\n",
    "        self.ac3 = torch.nn.ReLU().cuda()\n",
    "        self.fc4 = torch.nn.Linear(10, out_channels).cuda()\n",
    "        self.output = torch.nn.Sigmoid().cuda()\n",
    "        self.out_channels = out_channels\n",
    "        self.act_out = act_out\n",
    "        self.nlayers = nlayers\n",
    "        self.runbatchnorm = batchnorm\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.fc1(x)\n",
    "        #x = self.ac1(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = self.ac2(x)\n",
    "        x = self.fc3(x)\n",
    "        #x = self.ac3(x)\n",
    "        x = self.fc4(x)\n",
    "        #if self.runbatchnorm:\n",
    "        #    x = self.batchnorm(x)\n",
    "        #if self.act_out:\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f28b20fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define losses \n",
    "class BarlowTwinsLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, lambda_param=5e-3):\n",
    "        super(BarlowTwinsLoss, self).__init__()\n",
    "        self.lambda_param = lambda_param\n",
    "        self.device = torch.device('cuda:0')\n",
    "\n",
    "    def forward(self, z_a: torch.Tensor, z_b: torch.Tensor):\n",
    "        #self.device = (torch.device('cuda')if z_a.is_cuda else torch.device('cpu'))\n",
    "        # normalize repr. along the batch dimension\n",
    "        z_a_norm = (z_a - z_a.mean(0)) / z_a.std(0) # NxD\n",
    "        z_b_norm = (z_b - z_b.mean(0)) / z_b.std(0) # NxD\n",
    "\n",
    "        N = z_a.size(0)\n",
    "        D = z_a.size(1)\n",
    "\n",
    "        # cross-correlation matrix\n",
    "        c = torch.mm(z_a_norm.T, z_b_norm) / N # DxD\n",
    "        # loss\n",
    "        c_diff = (c - torch.eye(D, device=self.device)).pow(2) # DxD\n",
    "        # multiply off-diagonal elems of c_diff by lambda\n",
    "        c_diff[~torch.eye(D, dtype=bool)] *= self.lambda_param\n",
    "        loss = c_diff.sum()\n",
    "        return loss\n",
    "\n",
    "class CorrLoss(nn.Module):\n",
    "    def __init__(self, corr=False,sort_tolerance=1.0,sort_reg='l2'):\n",
    "        super(CorrLoss, self).__init__()\n",
    "        self.tolerance = sort_tolerance\n",
    "        self.reg       = sort_reg\n",
    "        self.corr      = corr\n",
    "        \n",
    "    def spearman(self, pred, target):\n",
    "        pred   = soft_rank(pred.cpu().reshape(1,-1),regularization=self.reg,regularization_strength=self.tolerance,)\n",
    "        target = soft_rank(target.cpu().reshape(1,-1),regularization=self.reg,regularization_strength=self.tolerance,)\n",
    "        #pred   = torchsort.soft_rank(pred.reshape(1,-1),regularization_strength=x)\n",
    "        #target = torchsort.soft_rank(target.reshape(1,-1),regularization_strength=x)\n",
    "        pred = pred - pred.mean()\n",
    "        pred = pred / pred.norm()\n",
    "        target = target - target.mean()\n",
    "        target = target / target.norm()\n",
    "        ret = (pred * target).sum()\n",
    "        if self.corr:\n",
    "            return (1-ret)*(1-ret)\n",
    "        else:\n",
    "            return ret*ret \n",
    "    \n",
    "    def forward(self, features, labels):\n",
    "        return self.spearman(features,labels)\n",
    "    \n",
    "class VICRegLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, lambda_param=1,mu_param=1,nu_param=20):\n",
    "        super(VICRegLoss, self).__init__()\n",
    "        self.lambda_param = lambda_param\n",
    "        self.mu_param = mu_param\n",
    "        self.nu_param = nu_param\n",
    "        #self.device = torch.device('cpu')\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.device = (torch.device('cuda')if x.is_cuda else torch.device('cpu'))\n",
    "        \n",
    "        x_scale = x\n",
    "        y_scale = y\n",
    "        repr_loss = F.mse_loss(x_scale, y_scale)\n",
    "        \n",
    "        #x = torch.cat(FullGatherLayer.apply(x), dim=0)\n",
    "        #y = torch.cat(FullGatherLayer.apply(y), dim=0)\n",
    "        x = x_scale - x_scale.mean(dim=0)\n",
    "        y = y_scale - y_scale.mean(dim=0)\n",
    "        N = x_scale.size(0)\n",
    "        D = x_scale.size(1)\n",
    "        \n",
    "        std_x = torch.sqrt(x_scale.var(dim=0) + 0.0001)\n",
    "        std_y = torch.sqrt(y_scale.var(dim=0) + 0.0001)\n",
    "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "        cov_x = (x_scale.T @ x_scale) / (N - 1)\n",
    "        cov_y = (y_scale.T @ y_scale) / (N - 1)\n",
    "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(D) + off_diagonal(cov_y).pow_(2).sum().div(D)\n",
    "\n",
    "        #loss = (self.lambda_param * repr_loss + self.mu_param * std_loss+ self.nu_param * cov_loss)\n",
    "        #print(repr_loss,cov_loss,std_loss)\n",
    "        return repr_loss,cov_loss,std_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c614dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/198 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingv1.shape torch.Size([6000, 4, 50])\n",
      "tensor([[[ 0.1519,  0.1099,  0.1014,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.1306,  0.1573, -0.0945,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0177,  0.0558, -0.0609,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000, -1.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.1604,  0.1471,  0.0788,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0099,  0.0526,  0.1177,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0465,  0.0560,  0.0247,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -1.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.3025,  0.1543,  0.0909,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0219,  0.0166, -0.0117,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0211,  0.0229,  0.0353,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.0000,  1.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1884,  0.1624,  0.1501,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0373,  0.0544,  0.0229,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0176,  0.0203,  0.0560,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.0000,  1.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0754,  0.0638,  0.0610,  ...,  0.0033,  0.0032,  0.0029],\n",
      "         [ 0.0155, -0.0609,  0.0195,  ..., -0.1151,  0.0530,  0.1809],\n",
      "         [ 0.1000, -0.0631, -0.0721,  ...,  0.0392,  0.2224, -0.3093],\n",
      "         [ 0.0000,  0.0000,  1.0000,  ...,  0.0000,  0.0000, -1.0000]],\n",
      "\n",
      "        [[ 0.1681,  0.1262,  0.0774,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0872, -0.0892,  0.0025,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0649,  0.0764, -0.0905,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.0000,  1.0000,  1.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0')\n",
      "Training done in 1.3815 seconds\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'out1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(n_encoded_nodes,\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,n_encoded_nodes\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m    128\u001b[0m axs[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;241m0.05\u001b[39m,\u001b[38;5;241m2.8\u001b[39m, loss_text, transform\u001b[38;5;241m=\u001b[39max\u001b[38;5;241m.\u001b[39mtransAxes)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mout1\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]): \n\u001b[1;32m    131\u001b[0m     outSig, massSig \u001b[38;5;241m=\u001b[39m out1_totSig[:, dim]\u001b[38;5;241m.\u001b[39mcopy(), trainingv1_mass_totSig[:]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    132\u001b[0m     outSig \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(outSig)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out1' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Training Loop Barlow DNN #########\n",
    "\n",
    "batchSize = 6000\n",
    "n_epochs = 10\n",
    "\n",
    "gnn = DNN(n_encoded_nodes)\n",
    "    \n",
    "loss = nn.BCELoss(reduction='mean')\n",
    "clr_criterion  = BarlowTwinsLoss(lambda_param=1.0)\n",
    "cor_criterion  = CorrLoss()\n",
    "acr_criterion  = CorrLoss(corr=True)\n",
    "\n",
    "BarlowLoss = True\n",
    "\n",
    "optimizer = optim.Adam(gnn.parameters(), lr = 0.0001)\n",
    "loss_vals_training = np.zeros(n_epochs)\n",
    "loss_std_training = np.zeros(n_epochs)\n",
    "loss_vals_validation = np.zeros(n_epochs)\n",
    "loss_std_validation = np.zeros(n_epochs)\n",
    "\n",
    "acc_vals_training = np.zeros(n_epochs)\n",
    "acc_vals_validation = np.zeros(n_epochs)\n",
    "acc_std_training = np.zeros(n_epochs)\n",
    "acc_std_validation = np.zeros(n_epochs)\n",
    "\n",
    "final_epoch = 0\n",
    "l_val_best = 99999\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "\n",
    "for m in range(n_epochs):\n",
    "    print(\"Epoch %s\\n\" % m)\n",
    "    torch.cuda.empty_cache()\n",
    "    final_epoch = m\n",
    "    lst = []\n",
    "    loss_val = []\n",
    "    loss_training = []\n",
    "    correct = []\n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    particleTrainingDataSig, jetMassTrainingDataSig = sklearn.utils.shuffle(particleTrainingDataSig, jetMassTrainingDataSig)\n",
    "    particleTrainingDataBkg, jetMassTrainingDataBkg = sklearn.utils.shuffle(particleTrainingDataBkg, jetMassTrainingDataBkg)\n",
    "    particleValidationDataSig, jetMassValidationDataSig = sklearn.utils.shuffle(particleValidationDataSig,\n",
    "                                                                                jetMassValidationDataSig)\n",
    "    particleValidationDataBkg, jetMassValidationDataBkg = sklearn.utils.shuffle(particleValidationDataBkg,\n",
    "                                                                                jetMassValidationDataBkg)\n",
    "    \n",
    "\n",
    "    out1_totSig = np.empty((0,n_encoded_nodes))\n",
    "    out1_totBkg = np.empty((0,n_encoded_nodes))\n",
    "\n",
    "    trainingv1_mass_totSig = []\n",
    "    trainingv1_mass_totBkg = []\n",
    "\n",
    "    #print(out1_tot)\n",
    "    for i in tqdm(range(int(0.8*datapoints/batchSize))): \n",
    "        #print('%s out of %s'%(i, int(particleTrainingData.shape[0]/batchSize)))\n",
    "        optimizer.zero_grad()\n",
    "        trainingvSig = torch.Tensor(particleTrainingDataSig[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingvBkg = torch.Tensor(particleTrainingDataBkg[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingvMassSig = torch.Tensor(jetMassTrainingDataSig[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingvMassBkg = torch.Tensor(jetMassTrainingDataBkg[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingv1 = torch.cat((trainingvSig[:int(batchSize/2)], \n",
    "                                trainingvBkg[:int(batchSize/2)]))\n",
    "        trainingv1_mass = torch.cat((trainingvMassSig[:int(batchSize/2)], \n",
    "                                trainingvMassBkg[:int(batchSize/2)]))\n",
    "        trainingv2 = torch.cat((trainingvSig[int(batchSize/2):], \n",
    "                                trainingvBkg[int(batchSize/2):]))\n",
    "        trainingv2_mass = torch.cat((trainingvMassSig[int(batchSize/2):], \n",
    "                                trainingvMassBkg[int(batchSize/2):]))\n",
    "        print(\"trainingv1.shape\",trainingv1.shape)\n",
    "        print(trainingv1)\n",
    "        break\n",
    "        # Calculate network output\n",
    "        out1 = gnn(trainingv1)\n",
    "        out2 = gnn(trainingv2)\n",
    "        \n",
    "        # Barlow Loss\n",
    "        lossClr = weightClr*clr_criterion(out1, out2)\n",
    "        \n",
    "        # AntiCorrelation\n",
    "        lossCorr1 = weightCorr1*acr_criterion(trainingv1_mass, out1[:,0])\n",
    "        lossCorr1 += weightCorr1*acr_criterion(trainingv2_mass, out2[:,0])\n",
    "        l = lossClr + lossCorr1\n",
    "       \n",
    "        # Correlation for rest of dimensions\n",
    "        for dim in range(out1.shape[1]-1): \n",
    "            l += weightCorr2*cor_criterion(out1[:,dim+1], trainingv1_mass)\n",
    "        \n",
    "        #l = weightClr*lossClr  + weightCorr1*lossCorr1 + weightCorr2*lossCorr2 + lossCorr3\n",
    "        \n",
    "        # Classical BCE loss\n",
    "        #trainingv = torch.FloatTensor(particleTrainingData[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        #out = gnn(trainingv)\n",
    "        #targetv = torch.FloatTensor(trainingLabels[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        #l = loss(out, targetv)\n",
    "        \n",
    "        \n",
    "        loss_training.append(l.item())\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        loss_string = \"Loss: %s\" % \"{0:.5f}\".format(l.item())\n",
    "        out1 = out1.cpu().detach().numpy()\n",
    "        out1_totSig = np.concatenate((out1_totSig,out1[:int(batchSize/2)]))\n",
    "        out1_totBkg = np.concatenate((out1_totBkg,out1[int(batchSize/2):]))\n",
    "\n",
    "        trainingv1_mass = trainingv1_mass.cpu().detach().numpy().tolist()\n",
    "        trainingv1_mass_totSig += trainingv1_mass[:int(batchSize/2)]\n",
    "        trainingv1_mass_totBkg += trainingv1_mass[int(batchSize/2):]\n",
    "\n",
    "        #print(\"SIG:\", trainingv1_mass_totSig)\n",
    "        #print(\"BKG:\", trainingv1_mass_totBkg)\n",
    "\n",
    "        del trainingvSig, trainingvBkg, l, trainingv1, trainingv2#, out1, out2, trainingv1_mass\n",
    "        torch.cuda.empty_cache()\n",
    "    #trainingv1_mass_tot = np.array(trainingv1_mass_tot)       \n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Training done in {toc - tic:0.4f} seconds\")\n",
    "    tic = time.perf_counter()\n",
    "\n",
    "    \n",
    "    plt.clf()\n",
    "    fig, axs = plt.subplots(n_encoded_nodes,2, figsize=(10,n_encoded_nodes*10))\n",
    "    \n",
    "    axs[0,0].text(0.05,2.8, loss_text, transform=ax.transAxes)\n",
    "\n",
    "    for dim in range(out1.shape[1]): \n",
    "        outSig, massSig = out1_totSig[:, dim].copy(), trainingv1_mass_totSig[:].copy()\n",
    "        outSig -= np.mean(outSig)\n",
    "        outSig /= np.std(outSig)\n",
    "        massSig -= np.mean(massSig)\n",
    "        massSig /= np.std(massSig)\n",
    "\n",
    "        outBkg, massBkg = out1_totBkg[:, dim].copy(), trainingv1_mass_totBkg[:].copy()\n",
    "        outBkg -= np.mean(outBkg)\n",
    "        outBkg /= np.std(outBkg)\n",
    "        massBkg -= np.mean(massBkg)\n",
    "        massBkg /= np.std(massBkg)\n",
    "\n",
    "        \n",
    "        axs[dim,0].text(0.8,1.03,f\"Z' Corr:  {np.corrcoef(outSig, massSig)[0,1] : .4f}\", transform=axs[dim,0].transAxes)\n",
    "        axs[dim,0].hist2d(outSig, trainingv1_mass_totSig[:], bins=30, )\n",
    "        axs[dim,1].text(0.8,1.03,f\"QCD Corr: {np.corrcoef(outBkg, massBkg)[0,1] : .4f}\", transform=axs[dim,1].transAxes)\n",
    "        axs[dim,1].hist2d(outBkg, trainingv1_mass_totBkg[:], bins=30, )\n",
    "        axs[dim,0].set_xlim([-3.,3.])\n",
    "        axs[dim,1].set_xlim([-3.,3.])\n",
    "        axs[dim,0].set_xlabel(f'Dimension {dim} output')\n",
    "        axs[dim,1].set_xlabel(f'Dimension {dim} output')\n",
    "        axs[dim,0].set_ylabel('Jet mass (GeV)')\n",
    "        \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(outdir+\"/\"+label+f\"_contrastivefigIN_trainingDataset_epoch{m}.jpg\")\n",
    "    del out1, out2, trainingv1_mass\n",
    "\n",
    "    \n",
    "    for i in range(int(0.1*datapoints/(batchSize))): \n",
    "        torch.cuda.empty_cache()\n",
    "        trainingvSig_val = torch.Tensor(particleValidationDataSig[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingvBkg_val = torch.Tensor(particleValidationDataBkg[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingvMassSig_val = torch.Tensor(jetMassValidationDataSig[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingvMassBkg_val = torch.Tensor(jetMassValidationDataBkg[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        targetv_val = torch.Tensor(validationLabels[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingv1_val = torch.cat((trainingvSig_val[:int(batchSize/2)], trainingvBkg_val[:int(batchSize/2)]))\n",
    "        trainingv2_val = torch.cat((trainingvSig_val[int(batchSize/2):], trainingvBkg_val[int(batchSize/2):]))\n",
    "        trainingv1_val_mass = torch.cat((trainingvMassSig_val[:int(batchSize/2)], \n",
    "                                trainingvMassBkg_val[:int(batchSize/2)]))\n",
    "        \n",
    "        # Barlow Loss\n",
    "        out1_val = gnn(trainingv1_val)\n",
    "        out2_val = gnn(trainingv2_val)\n",
    "        lossClr = weightClr*clr_criterion(out1_val, out2_val)\n",
    "        \n",
    "        # AntiCorrelation\n",
    "        lossCorr1 = weightCorr1*acr_criterion(trainingv1_val_mass, out1_val[:,0])\n",
    "        l_val = lossClr + lossCorr1\n",
    "       \n",
    "        # Correlation for rest of dimensions\n",
    "        for dim in range(out1_val.shape[1]-1): \n",
    "            l_val += (dim+1)*cor_criterion(out1_val[:,dim+1], trainingv1_val_mass)\n",
    "        \n",
    "        \n",
    "        # Classical validation\n",
    "        trainingv_val = torch.Tensor(particleValidationData[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        out = gnn(trainingv_val)\n",
    "        # l_val = loss(out, targetv_val)\n",
    "        lst.append(out.cpu().data.numpy())\n",
    "        loss_val.append(l_val.item())\n",
    "        correct.append(targetv_val.cpu())\n",
    "        out1_val = out1_val.cpu().detach().numpy()\n",
    "        trainingv1_val_mass = trainingv1_val_mass.cpu().detach().numpy()\n",
    "        \n",
    "        \n",
    "        del trainingvSig_val, trainingvBkg_val, targetv_val, trainingv1_val, trainingv2_val,out2_val\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.clf()\n",
    "    fig, axs = plt.subplots(n_encoded_nodes, figsize=(10,50))\n",
    "    for dim in range(out1_val.shape[1]): \n",
    "        axs[dim].plot(out1_val[:int(batchSize/2), dim], trainingv1_val_mass[:int(batchSize/2)], 'k+',c='r', alpha=0.5)\n",
    "        #plt.xlabel('%s dimension output'%(dim))\n",
    "        axs[dim].plot(out1_val[int(batchSize/2):, dim], trainingv1_val_mass[int(batchSize/2):], 'k+',c='b', alpha=0.5)\n",
    "\n",
    "        axs[dim].set_ylabel('sdmass')\n",
    "    plt.savefig(outdir+\"/\"+label+\"_contrastivefigIN_validationDataset.jpg\")\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    fig = corner.corner(out1_val[:int(batchSize/2)], color='red')\n",
    "    corner.corner(out1_val[int(batchSize/2):], fig=fig, color='blue')\n",
    "    plt.savefig(outdir+\"/\"+label+\"corner.jpg\")\n",
    "    plt.clf()\n",
    "    del out1_val, trainingv1_val_mass\n",
    "    #targetv_cpu = targetv.cpu().data.numpy()\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Evaluation done in {toc - tic:0.4f} seconds\")\n",
    "    l_val = np.mean(np.array(loss_val))\n",
    "\n",
    "    predicted = np.concatenate(lst) #(torch.FloatTensor(np.concatenate(lst))).to(device)\n",
    "    print('\\nValidation Loss: ', l_val)\n",
    "\n",
    "    l_training = np.mean(np.array(loss_training))\n",
    "    print('Training Loss: ', l_training)\n",
    "    val_targetv = np.concatenate(correct) #torch.FloatTensor(np.array(correct)).cuda()\n",
    "\n",
    "    torch.save(gnn.state_dict(), '%s/DNN_%s_last.pth'%(outdir,label))\n",
    "    if l_val < l_val_best:\n",
    "        print(\"new best model\")\n",
    "        l_val_best = l_val\n",
    "        torch.save(gnn.state_dict(), '%s/DNN_%s_best.pth'%(outdir,label))\n",
    "\n",
    "    print(val_targetv.shape, predicted.shape)\n",
    "    print(val_targetv, predicted)\n",
    "    acc_vals_validation[m] = accuracy_score(val_targetv[:,0],predicted[:,0]>0.5)\n",
    "    print(\"Validation Accuracy: \", acc_vals_validation[m])\n",
    "    loss_vals_training[m] = l_training\n",
    "    loss_vals_validation[m] = l_val\n",
    "    loss_std_validation[m] = np.std(np.array(loss_val))\n",
    "    loss_std_training[m] = np.std(np.array(loss_training))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if m > 8 and all(loss_vals_validation[max(0, m - 8):m] > min(np.append(loss_vals_validation[0:max(0, m - 8)], 200))):\n",
    "        print('Early Stopping...')\n",
    "        print(loss_vals_training, '\\n', np.diff(loss_vals_training))\n",
    "        break\n",
    "    torch.cuda.empty_cache()\n",
    "print('DONE with DNN training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b37a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "\n",
    "#r=torch.randperm(len(trainingLabels))\n",
    "x_torch=torch.load(f\"{outdir}/{label}_particleTrainingData.pt\").cuda()\n",
    "y_torch=torch.load(f\"{outdir}/{label}_trainingLabels.pt\").cuda()\n",
    "m_torch=torch.load(f\"{outdir}/{label}_jetMassTrainingData.pt\").cuda()\n",
    "\n",
    "gnn = DNN(n_encoded_nodes)\n",
    "gnn.load_state_dict(torch.load('%s/DNN_%s_best.pth'%(outdir,label), map_location=torch.device('cuda')))\n",
    "gnn.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_optimal_clr = gnn(x_torch)\n",
    "\n",
    "del x_torch\n",
    "torch.cuda.empty_cache()\n",
    "simple_model = simple_MLP(input_size=n_encoded_nodes-1)\n",
    "simple_optimizer = torch.optim.Adam(simple_model.parameters(), lr=.1) \n",
    "simple_criterion = torch.nn.BCELoss()\n",
    "\n",
    "for epoch in range(501):\n",
    "    simple_optimizer.zero_grad()\n",
    "    outputs = simple_model(outputs_optimal_clr[:,1:])\n",
    "    loss = simple_criterion(outputs,y_torch)\n",
    "    loss.backward()\n",
    "    simple_optimizer.step()\n",
    "    current_loss = float(loss.item())\n",
    "    if epoch % 10 == 1: \n",
    "        print(f\"Epoch {epoch} loss={current_loss:.5f}\")\n",
    "\n",
    "print(simple_model.state_dict())\n",
    "del simple_optimizer, loss, simple_model, simple_criterion\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69053458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "outputs = outputs.cpu().detach().numpy()\n",
    "y_torch = y_torch.cpu().detach().numpy()\n",
    "m_torch = m_torch.cpu().detach().numpy()\n",
    "\n",
    "fig, ax=plt.subplots()\n",
    "ax.hist(outputs[y_torch[:,1]==1][:,0],color=\"r\",bins=np.linspace(0.,1.,25),alpha=0.5,label=\"QCD\")\n",
    "ax.hist(outputs[y_torch[:,1]==0][:,0],color=\"b\",bins=np.linspace(0.,1.,25),alpha=0.5,label=\"Z'\")\n",
    "plt.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"Discriminator\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.text(0.45,1.03,loss_text, transform=ax.transAxes)\n",
    "plt.savefig(outdir+\"/discriminatorHist.png\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax=plt.subplots()\n",
    "#print(outputs[:,0].cpu().detach().numpy(),y_torch[:,0].cpu().detach().numpy().astype(bool))\n",
    "fpr, tpr, _ = roc_curve(y_torch[:,0],outputs[:,0],)\n",
    "ax.plot(fpr, tpr)\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.text(0.45,1.03,loss_text, transform=ax.transAxes)\n",
    "ax.text(0.75,0.10, f\"AUC={roc_auc_score(y_torch[:,0],outputs[:,0]) : 0.2f}\", transform=ax.transAxes)\n",
    "plt.savefig(outdir+\"/roc.png\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# Calculate mass distribution after cuts\n",
    "\n",
    "hist, edges = np.histogram(outputs[y_torch[:,1]==1][:,0], bins=np.linspace(0.,1.,100),density=True)\n",
    "cdf = np.cumsum(hist)*(edges[1]-edges[0])\n",
    "print(cdf)\n",
    "\n",
    "pctls = [0.,0.25,0.5,0.7,0.9,0.95,0.99]\n",
    "cuts = np.searchsorted(cdf,pctls)\n",
    "\n",
    "fig, ax=plt.subplots()\n",
    "\n",
    "qcd_idxs = y_torch[:,1]==1\n",
    "qcd_inclusive, _ = np.histogram(\n",
    "        m_torch[(qcd_idxs)],\n",
    "        density=True,\n",
    "    )\n",
    "for c,p in zip(cuts,pctls):\n",
    "    passing_idxs = outputs[:,0] > edges[c]\n",
    "    hist, bin_edges = np.histogram(\n",
    "        m_torch[(qcd_idxs&passing_idxs)], \n",
    "    )\n",
    "    N_passing = float(np.sum(hist))\n",
    "    qcd_passing = np.divide(hist,[N_passing])\n",
    "    jsd = scipy.spatial.distance.jensenshannon(qcd_passing, qcd_inclusive)\n",
    "\n",
    "    bins_centers = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "    ax.plot(\n",
    "        bins_centers, \n",
    "        qcd_passing,\n",
    "        label = f\"{(1-p)*100:.0f}% ({int(N_passing)}) JSD={0 if jsd == np.nan else jsd:.2f}\"\n",
    "    )\n",
    "ax.set_xlabel(\"Jet mass (GeV)\")\n",
    "ax.set_ylabel(\"a.u.\")\n",
    "plt.legend(loc=\"best\")\n",
    "ax.text(0.05,1.03,\"QCD jets\", transform=ax.transAxes)\n",
    "ax.text(0.45,1.03,loss_text, transform=ax.transAxes)\n",
    "plt.savefig(outdir+\"/sculptingQCD.png\")\n",
    "plt.show()\n",
    "print(cuts)\n",
    "\n",
    "plt.clf()\n",
    "fig, ax=plt.subplots()\n",
    "ax.hist2d(outputs[y_torch[:,1]==1][:,0],m_torch[y_torch[:,1]==1],bins=20)\n",
    "#ax.plot(m_torch.cpu().detach().numpy(),outputs[:,1].cpu().detach().numpy(),color=\"b\",label=\"Z'\")\n",
    "plt.legend(loc=\"best\")\n",
    "ax.set_ylabel(\"Jet mass (GeV)\")\n",
    "ax.set_xlabel(\"Discriminator\")\n",
    "ax.text(0.05,1.03,\"QCD jets\", transform=ax.transAxes)\n",
    "ax.text(0.45,1.03,loss_text, transform=ax.transAxes)\n",
    "plt.savefig(outdir+\"/discriminatorvsMassQCD.png\")\n",
    "plt.show()\n",
    "\n",
    "del y_torch, m_torch, outputs, outputs_optimal_clr\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"rm {outdir}/{label}_particleTrainingData.pt\")\n",
    "os.system(f\"rm {outdir}/{label}_jetMassTrainingData.pt\")\n",
    "os.system(f\"rm {outdir}/{label}_trainingLabels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6108ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
